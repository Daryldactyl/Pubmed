{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53159f77-8b21-403c-9ef2-4bf94d8a6ed7",
   "metadata": {},
   "source": [
    "# SkimLit ðŸ“„ðŸ”¥\n",
    "\n",
    "* Break down research papers (medical abstract) into more understandable or digestable sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deba705-3e2c-41f7-8f98-00050a1535ff",
   "metadata": {},
   "source": [
    "### What steps are we taking?\n",
    "\n",
    "1. Downloading a text dataset (PubMed 200K RCT)\n",
    "2. Writing a preprocessing function for our text data\n",
    "3. Set up multiple modelling experiments with different levels of embeddings\n",
    "4. Buld a multimodal model to take in different sources of data\n",
    "5. Replicate the model powering https://arxiv.org/abs/1710.06071\n",
    "6. Find the most wrong predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a49cd7-71d8-4828-aa05-e8a50a6d9147",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "Luckily for us, the author of the research paper has made the dataset publicly available: https://github.com/Franck-Dernoncourt/pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da9b5d5-baab-4ae7-85de-92a89b75e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pubmed-rct'...\n",
      "remote: Enumerating objects: 39, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25\u001b[K\n",
      "Receiving objects: 100% (39/39), 177.08 MiB | 7.11 MiB/s, done.\n",
      "Resolving deltas: 100% (15/15), done.\n",
      "\u001b[34mPubMed_200k_RCT\u001b[m\u001b[m\n",
      "\u001b[34mPubMed_200k_RCT_numbers_replaced_with_at_sign\u001b[m\u001b[m\n",
      "\u001b[34mPubMed_20k_RCT\u001b[m\u001b[m\n",
      "\u001b[34mPubMed_20k_RCT_numbers_replaced_with_at_sign\u001b[m\u001b[m\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
    "!ls pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c6a233f-4ff4-424c-99df-f77fd3ecd808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt   test.txt  train.txt\n"
     ]
    }
   ],
   "source": [
    "#We're starting with the smaller dataset for quicker testing, lets see what is in it!\n",
    "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d8618f-b054-4242-95bf-e97ff579c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bead4b1-460c-45c0-a5de-0ea1d31189ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/.ipynb_checkpoints']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df4a58-5cc4-4a3f-8f93-3eafb86717a9",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Let's get an idea for the dataset by Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974e8b9c-825b-49ff-b0d2-4bdece844b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read lines of a document\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename (a text filename) and returns the lines of text as a list.\n",
    "\n",
    "    Args:\n",
    "        filename: a string containing the target filepath.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings with one string per line from the target filename.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22404b5-cf28-4cd3-b9e2-37c5a6f5d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the training lines\n",
    "train_lines = get_lines(data_dir+'train.txt')\n",
    "train_lines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546e0ddf-79d0-40a8-94ee-3bae07cf0283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b71bb54-6d03-4152-8478-818f9fb28617",
   "metadata": {},
   "source": [
    "How will we separate the label from the text? \n",
    "\n",
    "```\n",
    "[{'line_number': 0,\n",
    "    'target': 'BACKGROUND',\n",
    "    'text': 'Emotional eating is associated with overeating and the development of obesity .\\n',\n",
    "    'total_lines': 11},\n",
    "    ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9e4db2-5d3a-4e42-8373-b7569ba23e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "    input_lines = get_lines(filename)\n",
    "    abstract_lines = \"\"\n",
    "    abstract_samples = []\n",
    "    \n",
    "    #Split lines from the given file into individual abstract lines\n",
    "    for line in input_lines:\n",
    "        if line.startswith('###'):\n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\"\n",
    "        elif line.isspace():\n",
    "            abstract_line_split = abstract_lines.splitlines()\n",
    "\n",
    "            #Iterate through each line in a single abstract and count them at the same time\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {}\n",
    "                target_text_split = abstract_line.split('\\t')\n",
    "                line_data['target'] = target_text_split[0]\n",
    "                line_data['text'] = target_text_split[1].lower()\n",
    "                line_data['line_number'] = abstract_line_number\n",
    "                line_data['total_lines'] = len(abstract_line_split) -1\n",
    "                abstract_samples.append(line_data)\n",
    "\n",
    "        else:\n",
    "            abstract_lines += line\n",
    "\n",
    "    return  abstract_samples        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1f0d1e-509f-4ef3-870a-78a266f42afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# Get the data and preprocess it\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + 'train.txt')\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + 'dev.txt')\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + 'test.txt')\n",
    "print(len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da23736-c710-4d33-9ccf-57b06dcf9dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first abstract of training data\n",
    "train_samples[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec734f-b7da-491f-9a8e-ea479840dfe1",
   "metadata": {},
   "source": [
    "### Now that the data is in a list of dictionaries we can turn it into a DataFrame for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "515f946f-6e3e-460f-bd9f-881a609493f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c2b24b-2eb9-4f87-913d-b3e0059bee3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distribution of labels\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fa1087-9de8-472e-93f2-0990932fb457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What about the length of different lines?\n",
    "train_df.total_lines.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9f0de-a95a-422b-aa31-140d327ba4b8",
   "metadata": {},
   "source": [
    "### Get lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad7dda7-eac0-439f-b49d-bddead4f4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstracts to lists\n",
    "train_sentences = train_df['text'].tolist()\n",
    "val_sentences = val_df['text'].tolist()\n",
    "test_sentences = test_df['text'].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827c5bff-9e7f-40f7-a256-9489d00e7ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e353e-c3c7-41fa-8f01-bd9dc82fbd10",
   "metadata": {},
   "source": [
    "## Make our Data Labels numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97866e23-4a89-4cae-9c4f-2193105e3c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1,1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1,1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1,1))\n",
    "\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62302d6-4632-4ee9-afb7-5539800e2c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
    "\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec96faf1-c196-4642-80e5-41b02bf04dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Class names and number of classes from the Label Encoder\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24392922-5833-401a-9346-4f719fdfefcb",
   "metadata": {},
   "source": [
    "## Model Building Experiments\n",
    "\n",
    "What will we be building?\n",
    "\n",
    "* Baseline: Naive Bayes with TF-IDF encoder\n",
    "1. Conv1D with token embeddings\n",
    "2. TensorFlow Hub Pretrained Feature Extractor\n",
    "3. Conv1D with character embeddings\n",
    "4. Pretrained token embeddings (same as 2) + character embeddings (same as 3)\n",
    "5. Pretrained token embeddings + character embeddings + positional embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbf115-18c2-453b-83f4-4b38ed856143",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef312f78-339f-4839-93ed-7a97e009db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff846952-0509-446a-8a8e-5596dd9907e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "baseline.fit(train_sentences, train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee71864d-bf12-48d5-b47f-cc24669daf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Achieves an Accuracy Score of:  72.18%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = baseline.score(val_sentences, val_labels_encoded)\n",
    "print(f'Baseline Model Achieves an Accuracy Score of: {baseline_score*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d982e7bd-082c-405d-b386-fb5b67ab65ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the baseline model\n",
    "baseline_preds = baseline.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567bdb7a-74e7-49f8-a55a-bc3b9deebcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.49      0.56      3449\n",
      "           1       0.65      0.59      0.61      4582\n",
      "           2       0.72      0.87      0.79      9964\n",
      "           3       0.75      0.14      0.23      2376\n",
      "           4       0.76      0.86      0.81      9841\n",
      "\n",
      "    accuracy                           0.72     30212\n",
      "   macro avg       0.71      0.59      0.60     30212\n",
      "weighted avg       0.72      0.72      0.70     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_labels_encoded, baseline_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc17bf9-881a-4af5-959d-ea8ec36d8f34",
   "metadata": {},
   "source": [
    "### Tokenize the text then turn it into an embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c74b58-27f9-46b3-ac45-85a392c2c66a",
   "metadata": {},
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92e6d83b-1810-4bd5-acd3-fce04b8979a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4741942\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import numpy as np\n",
    "\n",
    "#length of all sentences\n",
    "total = round(sum([len(i.split()) for i in train_sentences]))\n",
    "print(total)\n",
    "\n",
    "#average length of sentences\n",
    "average_len = round(total/len(train_sentences))\n",
    "print(average_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb17e850-a2f6-4263-aa53-dc853634c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "\n",
    "#What number covers 95% of our data?\n",
    "output_seq_len = int(np.percentile(sen_lens, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74db00e7-4aca-44ca-899c-15ecf918d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_len = 68000 #From table 2 in the paper: https://arxiv.org/abs/1710.06071\n",
    "max_len = 55\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_len,\n",
    "    output_sequence_length=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fc19077-a761-4901-8f64-f0c2be31b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "935f9f9b-2287-4bf6-941d-64c4db18a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:\n",
      " patients expressing h@ received a @-week induction course of intravesical bc-@ .\n",
      "\n",
      "Vectorized Version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(55,), dtype=int64, numpy=\n",
       "array([   12,  6296,   196,    80,     8,    89,   778,   656,     4,\n",
       "       12058,  3639,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display random sentence being vectorized\n",
    "import random\n",
    "\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f'Original Sentence:\\n {random_sentence}\\n\\nVectorized Version:')\n",
    "text_vectorizer(random_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ccc0b1-dad9-48a3-bd50-b5d79eaa52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 64841\n",
      "5 most common words: ['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were']\n",
      "5 least common words: ['aarm', 'aaqol', 'aaq', 'aanhui', 'aana', 'aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_10_words = words_in_vocab[:10]\n",
    "bottom_10_words = words_in_vocab[-10:]\n",
    "\n",
    "print(f'Number of words in vocab: {len(words_in_vocab)}')\n",
    "print(f'5 most common words: {top_10_words}')\n",
    "print(f'5 least common words: {bottom_10_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bf6cc-9d49-4dba-9e03-d6e2d69d8d46",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da4623b7-ab7d-4a32-9d6e-9b4cc5836c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x28a93c590>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding = Embedding(input_dim=max_vocab_len, output_dim=128, mask_zero=True)\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea1cfa62-eae6-4c5b-9744-595a8de3d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:\n",
      " adherence to ex was determined from exercise logs , ambulatory heart rate recordings of exercise , and weekly telephone contacts .\n",
      "\n",
      "Vectorized Version:\n",
      "tf.Tensor(\n",
      "[  429     6  3482    10   505    27   177 22648  1733   260    78  3870\n",
      "     4   177     3   632  1032  4546     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0], shape=(55,), dtype=int64)\n",
      "\n",
      "Embedding Version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(55, 128), dtype=float32, numpy=\n",
       "array([[-0.01426382,  0.02036412,  0.02916726, ..., -0.04192965,\n",
       "        -0.04415173,  0.02262126],\n",
       "       [-0.01937443, -0.04639683, -0.03277738, ...,  0.0319826 ,\n",
       "         0.02556853, -0.03052617],\n",
       "       [ 0.04853087, -0.00911927, -0.01224303, ...,  0.02849119,\n",
       "        -0.04674739, -0.04735545],\n",
       "       ...,\n",
       "       [ 0.03789096, -0.04744036, -0.0081799 , ..., -0.04134857,\n",
       "         0.04950932, -0.04803448],\n",
       "       [ 0.03789096, -0.04744036, -0.0081799 , ..., -0.04134857,\n",
       "         0.04950932, -0.04803448],\n",
       "       [ 0.03789096, -0.04744036, -0.0081799 , ..., -0.04134857,\n",
       "         0.04950932, -0.04803448]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(train_sentences)\n",
    "print(f'Original Sentence:\\n {random_sentence}\\n\\nVectorized Version:')\n",
    "print(text_vectorizer(random_sentence))\n",
    "print(f'\\nEmbedding Version:')\n",
    "embedding(text_vectorizer(random_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438ed98-4b18-43b4-b837-1a6851010021",
   "metadata": {},
   "source": [
    "### Conv1D with token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb838eef-b602-496b-b7c7-dcb1a1d2334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 55)                0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 55, 128)           8704000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 128)           82048     \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 128)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8803205 (33.58 MB)\n",
      "Trainable params: 8803205 (33.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Input, GlobalAveragePooling1D, Dense\n",
    "\n",
    "inputs = Input(shape=(1,), dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = Conv1D(128, 5, padding='same', activation='relu')(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = Dense(5, activation='sigmoid')(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b897e1b9-d891-4f3c-91c1-2e13eb0dd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer = tf.keras.optimizers.legacy.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5bb10ff-8cc2-46fb-b044-cbe049a7c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5627/5627 [==============================] - 98s 17ms/step - loss: 0.3999 - accuracy: 0.8576 - val_loss: 0.5248 - val_accuracy: 0.8113\n",
      "Epoch 2/5\n",
      "5627/5627 [==============================] - 97s 17ms/step - loss: 0.2315 - accuracy: 0.9208 - val_loss: 0.6054 - val_accuracy: 0.8009\n",
      "Epoch 3/5\n",
      "5627/5627 [==============================] - 98s 17ms/step - loss: 0.1480 - accuracy: 0.9498 - val_loss: 0.7671 - val_accuracy: 0.8024\n",
      "Epoch 4/5\n",
      "5627/5627 [==============================] - 98s 17ms/step - loss: 0.0972 - accuracy: 0.9669 - val_loss: 0.9378 - val_accuracy: 0.7932\n",
      "Epoch 5/5\n",
      "5627/5627 [==============================] - 98s 17ms/step - loss: 0.0682 - accuracy: 0.9773 - val_loss: 1.1284 - val_accuracy: 0.7898\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "history_1 = model_1.fit(tf.constant(train_sentences), train_labels_one_hot, epochs=5, validation_data=(tf.constant(val_sentences), val_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "124594a3-45fc-4ac9-a208-caac4ee8ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.8338521e-01, 2.6746831e-04, 5.1329040e-04, 1.3138378e-01,\n",
       "        5.2410714e-06],\n",
       "       [9.2729902e-01, 8.2772508e-02, 1.0133986e-03, 9.7349119e-01,\n",
       "        1.1072864e-04],\n",
       "       [3.8090047e-01, 1.3743627e-02, 1.5272902e-04, 9.9992269e-01,\n",
       "        3.4228504e-09],\n",
       "       ...,\n",
       "       [4.6881472e-09, 4.7641242e-05, 3.8779062e-01, 7.6289466e-06,\n",
       "        9.9980676e-01],\n",
       "       [6.3490275e-05, 9.9676037e-01, 1.4555639e-03, 2.1394916e-04,\n",
       "        3.4733970e-02],\n",
       "       [6.0555412e-05, 9.9991530e-01, 1.7508217e-05, 2.9306232e-06,\n",
       "        2.0587355e-02]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_probs = model_1.predict(tf.constant(val_sentences))\n",
    "model_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb499ecd-e3d8-4dff-81f6-2125b9f42f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 3, 3, ..., 4, 1, 1])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = tf.argmax(model_pred_probs, axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba1f2680-be9d-4041-a38d-80d51a20a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59      3449\n",
      "           1       0.75      0.66      0.70      4582\n",
      "           2       0.86      0.91      0.88      9964\n",
      "           3       0.54      0.61      0.57      2376\n",
      "           4       0.87      0.85      0.86      9841\n",
      "\n",
      "    accuracy                           0.79     30212\n",
      "   macro avg       0.72      0.72      0.72     30212\n",
      "weighted avg       0.79      0.79      0.79     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels_encoded, model_1_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd35f9-ab2b-4cd3-b595-903b50ec41e0",
   "metadata": {},
   "source": [
    "## Tensorflow Hub Pretrained Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74f57ec-6e7b-4459-8ddb-fad1eb80b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "encoding_layer = hub.KerasLayer('https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2',\n",
    "                               trainable=False,\n",
    "                               name='universal_sentence_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b8e87f8-0ca9-4e23-b3ec-1f0e335175d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence:\n",
      " in patients reloaded with @ mg prasugrel , cangrelor decreased pri at baseline ( p < @ ) and @ h ( p = @ ) ; levels of platelet reactivity comparable to those achieved with cangrelor were observed only at @ h ( p = @ ) .\n",
      "Sentence after embedding:\n",
      " [-0.03456404  0.02593905  0.01116584 -0.07088917  0.02529511  0.02007595\n",
      "  0.04942955 -0.00417012  0.01064496  0.05844885  0.08611968  0.06412391\n",
      " -0.00724038  0.05962229  0.04867586 -0.02030313 -0.08698953 -0.03696143\n",
      "  0.04124625 -0.02187959 -0.00359988  0.03054407 -0.0029204  -0.01694923\n",
      "  0.04413379  0.00616061  0.0112573   0.0068432  -0.00668528 -0.00056438]\n",
      "\n",
      "Length of sentence embedding: 512\n"
     ]
    }
   ],
   "source": [
    "random_train_sentence = random.choice(train_sentences)\n",
    "print(f'Random sentence:\\n {random_train_sentence}')\n",
    "use_embedded_sentence = encoding_layer([random_train_sentence])\n",
    "print(f'Sentence after embedding:\\n {use_embedded_sentence[0][:30]}\\n')\n",
    "print(f'Length of sentence embedding: {len(use_embedded_sentence[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff4722-7772-4fb3-b2fc-7dbcc0dfff22",
   "metadata": {},
   "source": [
    "### Build and fit the NLP Feature Extraction model using pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bc95328-5703-41c9-9221-e4c3459200c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5627/5627 [==============================] - 24s 4ms/step - loss: 0.7242 - accuracy: 0.7230 - val_loss: 0.6495 - val_accuracy: 0.7540\n",
      "Epoch 2/5\n",
      "5627/5627 [==============================] - 23s 4ms/step - loss: 0.6301 - accuracy: 0.7612 - val_loss: 0.6135 - val_accuracy: 0.7691\n",
      "Epoch 3/5\n",
      "5627/5627 [==============================] - 24s 4ms/step - loss: 0.5965 - accuracy: 0.7739 - val_loss: 0.5994 - val_accuracy: 0.7726\n",
      "Epoch 4/5\n",
      "5627/5627 [==============================] - 24s 4ms/step - loss: 0.5740 - accuracy: 0.7834 - val_loss: 0.5915 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "5627/5627 [==============================] - 23s 4ms/step - loss: 0.5570 - accuracy: 0.7896 - val_loss: 0.5924 - val_accuracy: 0.7759\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs = Input(shape=[], dtype='string')\n",
    "pretrained_embedding = encoding_layer(inputs) #Tokenizes and embeds \n",
    "x = Dense(128, activation='relu')(pretrained_embedding)\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer = tf.keras.optimizers.legacy.Adam(), metrics=['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(tf.constant(train_sentences), train_labels_one_hot, epochs=5, validation_data=(tf.constant(val_sentences), val_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33a8c74e-4f99-414f-8c42-35c783129bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.4129173e-01, 3.1844303e-02, 1.3627353e-05, 1.2648244e-01,\n",
       "        3.6793938e-04],\n",
       "       [7.1726751e-01, 1.2348766e-01, 2.9094415e-04, 1.5874912e-01,\n",
       "        2.0479868e-04],\n",
       "       [5.6258786e-01, 4.8345183e-03, 3.0350320e-03, 4.2772692e-01,\n",
       "        1.8157085e-03],\n",
       "       ...,\n",
       "       [4.5599323e-04, 1.1547338e-04, 5.2427799e-02, 1.5048681e-04,\n",
       "        9.4685018e-01],\n",
       "       [5.4804634e-02, 1.9047803e-01, 1.6468824e-01, 1.5979268e-02,\n",
       "        5.7404989e-01],\n",
       "       [6.6165058e-03, 9.9250484e-01, 5.3125079e-04, 1.6710943e-05,\n",
       "        3.3078538e-04]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_pred_probs = model_2.predict(tf.constant(val_sentences))\n",
    "model_2_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2eb36456-de25-4b09-bcd2-4ce4a19d4561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 0, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ce18730-36d9-4acf-b564-b408effb1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62      3449\n",
      "           1       0.72      0.62      0.66      4582\n",
      "           2       0.84      0.88      0.86      9964\n",
      "           3       0.70      0.49      0.58      2376\n",
      "           4       0.83      0.85      0.84      9841\n",
      "\n",
      "    accuracy                           0.78     30212\n",
      "   macro avg       0.73      0.70      0.71     30212\n",
      "weighted avg       0.77      0.78      0.77     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels_encoded, model_2_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcddd79-cb8d-4e38-bb0e-ec746b5ead9e",
   "metadata": {},
   "source": [
    "## Conv1D with Character Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19694e74-4abf-4e8c-8583-d8c4110ae2a8",
   "metadata": {},
   "source": [
    "### Create a character level Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44e620e-7b05-4192-a88c-1955ea05f7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i n   p a t i e n t s   r e l o a d e d   w i t h   @   m g   p r a s u g r e l   ,   c a n g r e l o r   d e c r e a s e d   p r i   a t   b a s e l i n e   (   p   <   @   )   a n d   @   h   (   p   =   @   )   ;   l e v e l s   o f   p l a t e l e t   r e a c t i v i t y   c o m p a r a b l e   t o   t h o s e   a c h i e v e d   w i t h   c a n g r e l o r   w e r e   o b s e r v e d   o n l y   a t   @   h   (   p   =   @   )   .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_chars(text):\n",
    "    return \" \".join(list(text))\n",
    "\n",
    "#Text splitting non-character level sequence into characters\n",
    "split_chars(random_train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5695f83-18b6-42d4-a66f-0a348bb33840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
       " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
       " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
       " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
       " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "train_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5759028d-2168-44bd-9b5e-6b65701a3247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Character Length\n",
    "chars_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(chars_lens)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e619f1f-ef8f-4e00-bf02-523f01912a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.41175e+05, 3.71110e+04, 1.60000e+03, 1.27000e+02, 2.10000e+01,\n",
       "        5.00000e+00, 1.00000e+00]),\n",
       " array([1.00000000e+00, 1.98857143e+02, 3.96714286e+02, 5.94571429e+02,\n",
       "        7.92428571e+02, 9.90285714e+02, 1.18814286e+03, 1.38600000e+03]),\n",
       " <BarContainer object of 7 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check the distribution of our sequence at a character level\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(chars_lens, bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28ebe5c4-dbd4-4e69-ac70-5c5fe61171b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the character length that covers 95% of sequences\n",
    "output_seq_char_len = int(np.percentile(chars_lens, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c173346-8df6-4ea9-927d-e3ea6b23490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all keyboard characters\n",
    "import string\n",
    "\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d83d9537-1019-41c2-8a8b-761eb26923d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHAR_TOKENS = len(alphabet) + 2\n",
    "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS, output_sequence_length=output_seq_char_len, name='char_vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32a06921-f649-4525-92f5-4cb9f0200851",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61ade87e-dd9b-4d61-8d6c-3864a7e79d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters in character vocab: 28\n",
      "5 most common: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 least common: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "#Check character vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f'Number of different characters in character vocab: {len(char_vocab)}')\n",
    "print(f'5 most common: {char_vocab[:5]}')\n",
    "print(f'5 least common: {char_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb726c5-f749-4d82-ab11-5c4d8aee2cde",
   "metadata": {},
   "source": [
    "### Create a character level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8fc572d-30a2-46e8-8c48-d4453d440949",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed = Embedding(input_dim=len(char_vocab),\n",
    "                      output_dim=25, #This is the output for the char embedding from the research paper\n",
    "                      mask_zero=True,\n",
    "                      name='char_embed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622004a-da06-4cdc-b384-022cec879abd",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60b7a7a1-e3bf-4ebb-9855-09cb3b733add",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(1,), dtype='string')\n",
    "tokenizer = char_vectorizer(inputs)\n",
    "embed = char_embed(tokenizer)\n",
    "x = Conv1D(128,8,activation='relu', padding='same')(embed)\n",
    "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d0f3936d-5c85-410d-881b-83c260d6c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " char_vectorizer (TextVecto  (None, 290)               0         \n",
      " rization)                                                       \n",
      "                                                                 \n",
      " char_embed (Embedding)      (None, 290, 25)           700       \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 290, 128)          25728     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43585 (170.25 KB)\n",
      "Trainable params: 43585 (170.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_3.compile(metrics=['accuracy'], loss='categorical_crossentropy', optimizer = tf.keras.optimizers.legacy.Adam())\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "798525ad-b339-4f61-aa70-2468246453af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38766d1a-c6e0-4b53-913f-6fb0c0fcefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5627/5627 [==============================] - 56s 10ms/step - loss: 0.7664 - accuracy: 0.7022 - val_loss: 0.6265 - val_accuracy: 0.7664\n",
      "Epoch 2/5\n",
      "5627/5627 [==============================] - 56s 10ms/step - loss: 0.6219 - accuracy: 0.7660 - val_loss: 0.6191 - val_accuracy: 0.7719\n",
      "Epoch 3/5\n",
      "5627/5627 [==============================] - 56s 10ms/step - loss: 0.5764 - accuracy: 0.7836 - val_loss: 0.6076 - val_accuracy: 0.7790\n",
      "Epoch 4/5\n",
      "5627/5627 [==============================] - 56s 10ms/step - loss: 0.5505 - accuracy: 0.7930 - val_loss: 0.6070 - val_accuracy: 0.7766\n",
      "Epoch 5/5\n",
      "5627/5627 [==============================] - 52s 9ms/step - loss: 0.5313 - accuracy: 0.8000 - val_loss: 0.5885 - val_accuracy: 0.7859\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "history_3 = model_3.fit(train_char_dataset, epochs=5, validation_data=val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "250b0e17-9abd-415e-82da-b39318ce4a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.2773120e-01, 5.9265369e-01, 2.8555509e-02, 9.5946625e-02,\n",
       "        5.5112842e-02],\n",
       "       [5.4904866e-01, 2.4641748e-01, 8.1020873e-03, 1.7474245e-01,\n",
       "        2.1689346e-02],\n",
       "       [4.0063685e-01, 6.0791016e-04, 2.8923438e-03, 5.9561878e-01,\n",
       "        2.4413031e-04],\n",
       "       ...,\n",
       "       [4.7767440e-07, 9.1349866e-05, 1.7625453e-03, 7.9445346e-07,\n",
       "        9.9814487e-01],\n",
       "       [5.2010844e-04, 1.8064020e-02, 2.9909359e-02, 4.6087932e-04,\n",
       "        9.5104569e-01],\n",
       "       [2.4998426e-03, 9.9346876e-01, 7.7318936e-04, 9.6100155e-04,\n",
       "        2.2972091e-03]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "252f3c53-303b-4079-8c35-02f517fb8a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 0, 3, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
    "model_3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7bdc5ac2-fc66-40a3-9d0a-ca5cadd0336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.61      3449\n",
      "           1       0.74      0.62      0.68      4582\n",
      "           2       0.84      0.88      0.86      9964\n",
      "           3       0.78      0.50      0.61      2376\n",
      "           4       0.79      0.91      0.85      9841\n",
      "\n",
      "    accuracy                           0.79     30212\n",
      "   macro avg       0.76      0.70      0.72     30212\n",
      "weighted avg       0.78      0.79      0.78     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels_encoded, model_3_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fac0c2-029b-44dd-9f3e-47153a30b3e1",
   "metadata": {},
   "source": [
    "## Combining Pretrained token embeddings + Character embeddings\n",
    "\n",
    "1. Create a token-level embedding model (similar `model_1`)\n",
    "2. Create a character-level model (similar to `model_3` with a slight modification)\n",
    "3. Combine 1 & 2 with a concatenate (`layers.Concatenate`)\n",
    "4. Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of the research paper\n",
    "5. Construct a model which takes token and character level sequences as input and produce sequence label probabilities of ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9c1caf5-a0d8-4c35-ace6-d8d8c7c7df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Setup the token inputs model\n",
    "token_inputs = layers.Input(shape=[], dtype=tf.string, name='token_input')\n",
    "token_embeddings = encoding_layer(token_inputs)\n",
    "token_output = layers.Dense(128, activation='relu')(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs, outputs=token_output)\n",
    "\n",
    "# Create the character level model\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n",
    "\n",
    "# Combine the models with concatenate\n",
    "token_char_concat = layers.Concatenate(name='token_char_hybrid')([token_model.output, char_model.output])\n",
    "\n",
    "# Build output layers - add in dropout as in 4.2 from research paper\n",
    "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = layers.Dense(128, activation='relu')(combined_dropout)\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "output_layer = layers.Dense(5, activation='softmax')(final_dropout)\n",
    "\n",
    "# Construct the final model\n",
    "model_4 = tf.keras.Model(inputs = [token_model.input, char_model.input], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7d7560c-b78a-4915-8929-1586d518630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " char_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " token_input (InputLayer)    [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVecto  (None, 290)                  0         ['char_input[0][0]']          \n",
      " rization)                                                                                        \n",
      "                                                                                                  \n",
      " universal_sentence_encoder  (None, 512)                  2567978   ['token_input[0][0]']         \n",
      "  (KerasLayer)                                            24                                      \n",
      "                                                                                                  \n",
      " char_embed (Embedding)      (None, 290, 25)              700       ['char_vectorizer[0][0]']     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  65664     ['universal_sentence_encoder[1\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 48)                   9600      ['char_embed[0][0]']          \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " token_char_hybrid (Concate  (None, 176)                  0         ['dense_4[0][0]',             \n",
      " nate)                                                               'bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 176)                  0         ['token_char_hybrid[0][0]']   \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 128)                  22656     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 5)                    645       ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256897089 (979.98 MB)\n",
      "Trainable params: 99265 (387.75 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33eab464-3c2d-4a0c-afc3-f833134eb9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.legacy.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16375857-44ee-492c-8ef5-5bca996e3135",
   "metadata": {},
   "source": [
    "### Combining token and character data into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "189f349d-d729-4a3f-915d-8b8d75c170f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine chars and tokens\n",
    "train_token_char_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_token_char_data, train_char_token_labels))\n",
    "\n",
    "#Prefetch and batch train data\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c22ec442-8300-46ea-b0b6-2091e2f8160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_token_char_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_token_char_data, val_char_token_labels))\n",
    "\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65ecfa74-1da9-4b6a-943f-09d32407dc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>,\n",
       " <_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char_token_dataset, val_char_token_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515972dc-5ef2-46bd-82bf-13cc5b4c3097",
   "metadata": {},
   "source": [
    "### Fitting model with hybrid embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c856570-ae30-46c6-8a27-07c58ddd22e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.7915 - accuracy: 0.6981 - val_loss: 0.7256 - val_accuracy: 0.7281\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 28s 50ms/step - loss: 0.7592 - accuracy: 0.7083 - val_loss: 0.6935 - val_accuracy: 0.7364\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 28s 50ms/step - loss: 0.7562 - accuracy: 0.7095 - val_loss: 0.6807 - val_accuracy: 0.7394\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 28s 50ms/step - loss: 0.7304 - accuracy: 0.7248 - val_loss: 0.6606 - val_accuracy: 0.7493\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.7404 - accuracy: 0.7196 - val_loss: 0.6485 - val_accuracy: 0.7513\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_4.fit(train_char_token_dataset, epochs=5, steps_per_epoch=int(0.1 * len(train_char_token_dataset)), validation_data=val_char_token_dataset, validation_steps=int(0.1 * len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6926734-f7b3-4086-9012-fa47fa0dc4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 11s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.3170544e-01, 2.3859826e-01, 6.6737402e-03, 2.1439488e-01,\n",
       "        8.6277192e-03],\n",
       "       [4.1233420e-01, 4.4935280e-01, 5.0584115e-03, 1.2788005e-01,\n",
       "        5.3745159e-03],\n",
       "       [3.1826845e-01, 3.4666885e-02, 6.4133622e-02, 5.6788933e-01,\n",
       "        1.5041752e-02],\n",
       "       ...,\n",
       "       [3.5683109e-04, 2.7701485e-03, 6.6153131e-02, 1.6673804e-04,\n",
       "        9.3055314e-01],\n",
       "       [9.6102655e-03, 4.2361300e-02, 3.4710699e-01, 4.2434372e-03,\n",
       "        5.9667796e-01],\n",
       "       [2.2583662e-01, 5.5096298e-01, 1.9277522e-01, 1.1197063e-02,\n",
       "        1.9228131e-02]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
    "model_4_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cf1e0bd-7705-4496-aaf3-10b607ba623a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
    "model_4_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e734e375-8b7d-4db6-ac32-306583fcbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56      3449\n",
      "           1       0.67      0.58      0.62      4582\n",
      "           2       0.77      0.89      0.83      9964\n",
      "           3       0.71      0.53      0.61      2376\n",
      "           4       0.82      0.81      0.81      9841\n",
      "\n",
      "    accuracy                           0.75     30212\n",
      "   macro avg       0.71      0.67      0.68     30212\n",
      "weighted avg       0.74      0.75      0.74     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_labels_encoded, model_4_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c76230-9cf7-426d-a97a-09bfee32cb0c",
   "metadata": {},
   "source": [
    "## Model 5 Including positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "947baccb-69f6-4aa5-911b-d13c687a783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abeaa9f6-f7c4-4701-9f0e-4a19ced5dd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "line_number\n",
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create positional embeddings\n",
    "train_df['line_number'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da6a144c-2a4c-41bd-8699-c42f9ae35db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check distribution of line number column\n",
    "train_df.line_number.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57f3fcc2-8bd3-4f74-9d6f-4804d307570d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 15), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TensorFlow to create one hot encoded tensors\n",
    "train_line_numbers_one_hot = tf.one_hot(train_df['line_number'].to_numpy(), depth=15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df['line_number'].to_numpy(), depth=15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df['line_number'].to_numpy(), depth=15)\n",
    "train_line_numbers_one_hot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bff28da4-9a6d-48d4-8bfe-8c456c259d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_lines\n",
       "11    24468\n",
       "10    23639\n",
       "12    22113\n",
       "9     19400\n",
       "13    18438\n",
       "14    14610\n",
       "8     12285\n",
       "15    10768\n",
       "7      7464\n",
       "16     7429\n",
       "17     5202\n",
       "6      3353\n",
       "18     3344\n",
       "19     2480\n",
       "20     1281\n",
       "5      1146\n",
       "21      770\n",
       "22      759\n",
       "23      264\n",
       "4       215\n",
       "24      200\n",
       "25      182\n",
       "26       81\n",
       "28       58\n",
       "3        32\n",
       "30       31\n",
       "27       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['total_lines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55eb321b-7aee-4a78-a84d-0803f30de012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['total_lines'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1401e3a9-682c-47b6-a546-b2d26902aa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total_line_one_hot = tf.one_hot(train_df['total_lines'].to_numpy(), depth=20)\n",
    "val_total_line_one_hot = tf.one_hot(val_df['total_lines'].to_numpy(), depth=20)\n",
    "test_total_line_one_hot = tf.one_hot(test_df['total_lines'].to_numpy(), depth=20)\n",
    "train_total_line_one_hot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900dd064-263b-4535-ad7a-d098b205a3c2",
   "metadata": {},
   "source": [
    "### Building the TriBrid Embedding model\n",
    "\n",
    "1. Create token level model\n",
    "2. Create character level model\n",
    "3. Create a model for the line number feature\n",
    "4. Create a model for the total lines feature\n",
    "5. Combine the outputs of 1&2 using concatenate\n",
    "6. Combine the outputs of 3, 4, 5 using concat\n",
    "7. Create output layer to accept the tribred model\n",
    "8. Combine the inputs of 1,2,3,4 and outputs of into a tf.keras.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f57af47-72df-48c3-8234-4302f15976ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([180040, 15]), TensorShape([180040, 20]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_line_numbers_one_hot.shape, train_total_line_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed97147f-a6fd-479d-963d-44eff41baf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Token level Inputs\n",
    "token_inputs = layers.Input(shape=[], dtype='string', name='token_inputs')\n",
    "token_embeddings = encoding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation='relu')(token_embeddings)\n",
    "token_model = tf.keras.Model(token_inputs, token_outputs)\n",
    "\n",
    "#2 Char level Inputs\n",
    "char_inputs = layers.Input(shape=(1,), dtype='string', name='char_inputs')\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(char_inputs, char_bi_lstm)\n",
    "\n",
    "#3 Line number Inputs\n",
    "line_inputs = layers.Input(shape=(15,), dtype=tf.float32)\n",
    "# line_feed = layers.Dense(64, activation='relu')\n",
    "line_outputs = layers.Dense(32, activation='relu')(line_inputs)\n",
    "line_model = tf.keras.Model(line_inputs, line_outputs)\n",
    "\n",
    "#4 Total Lines Inputs\n",
    "total_line_inputs = layers.Input(shape=(20,), dtype=tf.float32)\n",
    "total_line_outputs = layers.Dense(32, activation='relu')(total_line_inputs)\n",
    "total_line_model = tf.keras.Model(total_line_inputs, total_line_outputs)\n",
    "\n",
    "#5 Combine token and char embeddings into hybrid eembedding\n",
    "combined_embeddings = layers.Concatenate(name='char_token_hybrid')([token_model.output, char_model.output])\n",
    "x = layers.Dense(256, activation='relu')(combined_embeddings)\n",
    "combined_dropout = layers.Dropout(0.5)(x)\n",
    "\n",
    "#6 Combine positional embedding with combined token and char embeddings\n",
    "tribrid_embeddings = layers.Concatenate(name='char_token_positional')([line_model.output, total_line_model.output, combined_dropout])\n",
    "# y = layers.Bidirectional(layers.LSTM(24))(tribrid_embeddings)\n",
    "\n",
    "#7 Create output layer\n",
    "output_layer = layers.Dense(5, activation='softmax')(tribrid_embeddings)\n",
    "\n",
    "#8 Put together model with all kinds of inputs\n",
    "model_5 = tf.keras.Model(inputs=[line_model.input, total_line_model.input, token_model.input, char_model.input],\n",
    "                        outputs=output_layer, name='Tribrid_Embedding_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5061c827-c98e-4935-8918-91fbb1af0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Tribrid_Embedding_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " char_inputs (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " token_inputs (InputLayer)   [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVecto  (None, 290)                  0         ['char_inputs[0][0]']         \n",
      " rization)                                                                                        \n",
      "                                                                                                  \n",
      " universal_sentence_encoder  (None, 512)                  2567978   ['token_inputs[0][0]']        \n",
      "  (KerasLayer)                                            24                                      \n",
      "                                                                                                  \n",
      " char_embed (Embedding)      (None, 290, 25)              700       ['char_vectorizer[5][0]']     \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 128)                  65664     ['universal_sentence_encoder[6\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " bidirectional_6 (Bidirecti  (None, 48)                   9600      ['char_embed[5][0]']          \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " char_token_hybrid (Concate  (None, 176)                  0         ['dense_26[0][0]',            \n",
      " nate)                                                               'bidirectional_6[0][0]']     \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)       [(None, 15)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 256)                  45312     ['char_token_hybrid[0][0]']   \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 32)                   512       ['input_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 32)                   672       ['input_12[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 256)                  0         ['dense_29[0][0]']            \n",
      "                                                                                                  \n",
      " char_token_positional (Con  (None, 320)                  0         ['dense_27[0][0]',            \n",
      " catenate)                                                           'dense_28[0][0]',            \n",
      "                                                                     'dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 5)                    1605      ['char_token_positional[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256921889 (980.08 MB)\n",
      "Trainable params: 124065 (484.63 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7f1010ed-d3ba-43f8-aa4d-4ebd21236c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), metrics=['accuracy'], optimizer = tf.keras.optimizers.legacy.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f75582a4-a921-456f-9971-1a6d1f46970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and validation datasets (with all four kinds of input data)\n",
    "train_char_token_pos_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, train_total_line_one_hot, train_sentences, train_chars))\n",
    "train_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "train_char_token_pos_dataset = tf.data.Dataset.zip((train_char_token_pos_data, train_char_token_pos_labels))\n",
    "train_char_token_pos_dataset = train_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_char_token_pos_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot, val_total_line_one_hot, val_sentences, val_chars))\n",
    "val_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_pos_dataset = tf.data.Dataset.zip((val_char_token_pos_data, val_char_token_pos_labels))\n",
    "val_char_token_pos_dataset = val_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8c943c2-c885-463c-8c45-681ccdda745c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>,\n",
       " <_PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char_token_pos_dataset, val_char_token_pos_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6005b36d-2806-43f5-a890-c89f1f4f324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 32s 53ms/step - loss: 1.0964 - accuracy: 0.7219 - val_loss: 0.9871 - val_accuracy: 0.8039\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.9689 - accuracy: 0.8148 - val_loss: 0.9525 - val_accuracy: 0.8231\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.9511 - accuracy: 0.8227 - val_loss: 0.9387 - val_accuracy: 0.8305\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.9395 - accuracy: 0.8337 - val_loss: 0.9325 - val_accuracy: 0.8351\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 29s 51ms/step - loss: 0.9365 - accuracy: 0.8346 - val_loss: 0.9265 - val_accuracy: 0.8421\n"
     ]
    }
   ],
   "source": [
    "history_5 = model_5.fit(train_char_token_pos_dataset, epochs=5, steps_per_epoch=int(0.1 * len(train_char_token_pos_dataset)), validation_data=val_char_token_pos_dataset, validation_steps=int(0.1 * len(val_char_token_pos_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "24c9b1d1-d723-4349-85fd-7c0cda24c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 11s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.59965914, 0.07942806, 0.01535892, 0.2795003 , 0.02605364],\n",
       "       [0.6358556 , 0.08002486, 0.07262845, 0.19868319, 0.01280787],\n",
       "       [0.34360915, 0.10050704, 0.14111803, 0.36575025, 0.0490155 ],\n",
       "       ...,\n",
       "       [0.03110188, 0.05442756, 0.03334283, 0.02459825, 0.8565295 ],\n",
       "       [0.02157629, 0.29239386, 0.09795199, 0.02123627, 0.5668416 ],\n",
       "       [0.11479076, 0.67241573, 0.11789137, 0.02607216, 0.06882991]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_pred_probs = model_5.predict(val_char_token_pos_dataset, verbose=1)\n",
    "model_5_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c20c6bb-a514-43fd-b361-af94d648b31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
    "model_5_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0859b63f-336d-479f-8836-45ce3a386696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.75      3449\n",
      "           1       0.88      0.82      0.85      4582\n",
      "           2       0.83      0.94      0.88      9964\n",
      "           3       0.81      0.48      0.61      2376\n",
      "           4       0.89      0.85      0.87      9841\n",
      "\n",
      "    accuracy                           0.84     30212\n",
      "   macro avg       0.83      0.78      0.79     30212\n",
      "weighted avg       0.84      0.84      0.84     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels_encoded, model_5_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ba44bd9-8f39-4cc7-adcf-64b5ba7e102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5627/5627 [==============================] - 278s 49ms/step - loss: 0.9190 - accuracy: 0.8471 - val_loss: 0.9085 - val_accuracy: 0.8484\n",
      "Epoch 2/5\n",
      "5627/5627 [==============================] - 277s 49ms/step - loss: 0.9024 - accuracy: 0.8594 - val_loss: 0.9036 - val_accuracy: 0.8507\n",
      "Epoch 3/5\n",
      "5627/5627 [==============================] - 278s 49ms/step - loss: 0.8928 - accuracy: 0.8664 - val_loss: 0.8995 - val_accuracy: 0.8574\n",
      "Epoch 4/5\n",
      "5627/5627 [==============================] - 278s 49ms/step - loss: 0.8855 - accuracy: 0.8719 - val_loss: 0.9013 - val_accuracy: 0.8551\n",
      "Epoch 5/5\n",
      "5627/5627 [==============================] - 279s 50ms/step - loss: 0.8794 - accuracy: 0.8764 - val_loss: 0.9004 - val_accuracy: 0.8554\n"
     ]
    }
   ],
   "source": [
    "history_6 = model_5.fit(train_char_token_pos_dataset, epochs=5, validation_data=val_char_token_pos_dataset, validation_steps=int(0.1 * len(val_char_token_pos_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e483d264-8916-4e5a-a640-2078f65afad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_char_token_pos_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot, test_total_line_one_hot, test_sentences, test_chars))\n",
    "test_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
    "test_char_token_pos_dataset = tf.data.Dataset.zip((test_char_token_pos_data, test_char_token_pos_labels))\n",
    "test_char_token_pos_dataset = test_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08179ce1-8ef9-4d29-be94-68014036a3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942/942 [==============================] - 10s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30135, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_test_pred_probs = model_5.predict(test_char_token_pos_dataset)\n",
    "model_5_test_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1be92af1-cd92-4bda-9d82-dae90ac29982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36032778, 0.09056252, 0.0736318 , 0.35792372, 0.11755422],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_test_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "730f1969-129c-49b9-bd87-1f5782552e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([0, 2, 2, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_test_preds = tf.argmax(model_5_test_pred_probs, axis=1)\n",
    "model_5_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70f31759-103e-473d-9f9d-2d628845dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942/942 [==============================] - 10s 10ms/step - loss: 0.9050 - accuracy: 0.8504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9049815535545349, 0.8503733277320862]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(test_char_token_pos_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "72240b4b-2d78-42bd-b048-ab94f2de250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      3621\n",
      "           1       0.88      0.86      0.87      4571\n",
      "           2       0.89      0.90      0.89      9897\n",
      "           3       0.80      0.49      0.61      2333\n",
      "           4       0.86      0.89      0.88      9713\n",
      "\n",
      "    accuracy                           0.85     30135\n",
      "   macro avg       0.83      0.79      0.80     30135\n",
      "weighted avg       0.85      0.85      0.85     30135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_encoded, model_5_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b29b5-6f6d-432b-bc59-d73ce09b0297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
